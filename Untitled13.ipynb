{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsEAHmculvNM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Load the eligibility criteria text file\n",
        "filename = \"concatenated_text.txt\"\n",
        "\n",
        "import chardet\n",
        "\n",
        "# Detect the encoding of the file\n",
        "with open(filename, 'rb') as f:\n",
        "    result = chardet.detect(f.read())\n",
        "\n",
        "# Load the file with the detected encoding\n",
        "raw_text = open(filename, encoding=result['encoding']).read()\n",
        "\n",
        "# Create a mapping of unique characters to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "# Prepare the data for training\n",
        "seq_length = 50\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(raw_text) - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "# Reshape the input data\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# Normalize the input data\n",
        "X = X / float(len(chars))\n",
        "\n",
        "# One-hot encode the output data\n",
        "y = np_utils.to_categorical(dataY)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=5, batch_size=128)\n",
        "\n",
        "# Use the trained model to predict the eligibility criteria\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def predict_eligibility_criteria(model, tender_text):\n",
        "    # Encode the input text\n",
        "    encoded_text = tokenizer.encode_plus(tender_text, max_length=50, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    x_input = encoded_text['input_ids'].numpy().squeeze()\n",
        "    x_input = np.reshape(x_input, (1, seq_length, 1))\n",
        "    x_input = x_input / float(len(chars))\n",
        "    # Generate the predicted output\n",
        "    y_output = model.predict(x_input, verbose=0)\n",
        "    # Convert the predicted output to text\n",
        "    index = np.argmax(y_output)\n",
        "    result = chars[index]\n",
        "    return result\n",
        "\n",
        "model.save(\"eligibility_criteria_model.h5\")\n",
        "from keras.models import load_model\n",
        "model = load_model(\"eligibility_criteria_model.h5\")\n",
        "\n",
        "def predict_eligibility_criteria(model, tender_text):\n",
        "    # Encode the input text\n",
        "    encoded_text = tokenizer.encode_plus(tender_text, max_length=50, padding='max_length', truncation=True, return_tensors='pt')\n",
        "    x_input = encoded_text['input_ids'].numpy().squeeze()\n",
        "    x_input = np.reshape(x_input, (1, seq_length, 1))\n",
        "    x_input = x_input / float(len(chars))\n",
        "    # Generate the predicted output\n",
        "    y_output = model.predict(x_input, verbose=0)\n",
        "    # Convert the predicted output to text\n",
        "    index = np.argmax(y_output)\n",
        "    result = chars[index]\n",
        "    return result\n"
      ]
    }
  ]
}